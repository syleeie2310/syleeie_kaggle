{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Book 싸이그래머 Remind 스터디\n",
    "\n",
    "#### Ref1 : https://www.slideshare.net/blaswan/energy-based-models-and-boltzmann-machines\n",
    "#### Ref2 : http://abipictures.tistory.com/773\n",
    "#### Ref3 : http://wjyoo80.tistory.com/entry/Restricted-Boltzmann-Machines-RBM\n",
    "#### Ref4 : http://www.navisphere.net/2341/learning-deep-architectures-for-ai-5/\n",
    "#### Ref5 : http://khanrc.tistory.com/entry/Restricted-Boltzmann-Machine\n",
    "#### Ref6 : http://www.wikiwand.com/ko/%EB%94%A5_%EB%9F%AC%EB%8B%9D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 20 Deep Generative Models\n",
    "\n",
    "\n",
    "#### 4/26 Remind Part1 - 2 \n",
    "- 20.1 Boltzmann Machines (4/26)\n",
    "- 20.2 Restricted Boltzmann Machines (4/26)\n",
    "    - 20.2.1 Conditional Distributions (4/26)\n",
    "    - 20.2.2 Training Restricted Boltzmann Machines (4/26)\n",
    "- 20.3 Deep Belief Networks (4/26)\n",
    "\n",
    "\n",
    "#### 5/24 Remind Part1 - 3 \n",
    "- 20.4 Deep Boltzmann Machines \n",
    "    - 20.4.1 Interesting Properties\n",
    "    - 20.4.2 DBM Mean Field Inference\n",
    "    - 20.4.3 DBM Parameter Learning\n",
    "    - 20.4.4 Layer-Wise Pretraining\n",
    "    - 20.4.5 Jointly Training Deep Boltzmann Machines\n",
    "- 20.5 Boltzmann Machines for Real-Valued Data \n",
    "    - 20.5.1 Gaussian-Bernoulli RBMs\n",
    "    - 20.5.2 Undirected Models of Conditional Covariance\n",
    "- 20.6 Convolutional Boltzmann Machines \n",
    "- 20.7 Boltzmann Machines for Structured or Sequential Outputs\n",
    "- 20.8 Other Boltzmann Machines\n",
    "- 20.9 Back-Propagation through Random Operations \n",
    "    - 20.9.1 Back-Propagating through Discrete Stochastic Operations\n",
    "    \n",
    "#### 6/7 Remind Part1 - 4\n",
    "- 20.10 Directed Generative Nets\n",
    "    - 20.10.1 Sigmoid Belief Nets\n",
    "    - 20.10.2 Diﬀerentiable Generator Nets\n",
    "    - 20.10.3 Variational Autoencoders\n",
    "    - 20.10.4 Generative Adversarial Networks\n",
    "    - 20.10.5 Generative Moment Matching Networks\n",
    "    - 20.10.6 Convolutional Generative Networks\n",
    "    - 20.10.7 Auto-Regressive Networks\n",
    "    - 20.10.8 Linear Auto-Regressive Networks\n",
    "    - 20.10.9 Neural Auto-Regressive Networks\n",
    "    - 20.10.10 NADE\n",
    "- 20.11 Drawing Samples from Autoencoders\n",
    "    - 20.11.1 Markov Chain Associated with any Denoising Autoen-coder\n",
    "    - 20.11.2 Clamping and Conditional Sampling\n",
    "    - 20.11.3 Walk-Back Training Procedure\n",
    "- 20.12 Generative Stochastic Networks\n",
    "    - 20.12.1 Discriminant GSNs\n",
    "- 20.13 Other Generation Schemes\n",
    "- 20.14 Evaluating Generative Models\n",
    "- 20.15 Conclusion\n",
    "\n",
    "\n",
    "### http://www.deeplearningbook.org/contents/generative_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 데이터의 생성모델\n",
    "- 숫자 인식 (사람 등의 차이에 의한 변동) 벡터 x의 공간 전체에 걸치지는 않음.\n",
    "- 변동 폭은 상당히 제한되어 '치우쳐' 있다고 할 수 있음\n",
    "- 이 치우침을 포착하여 나타나기 위해 낱낱의 데이터 x가 어떤 미지의 확률 분포, Pg(x)를 따라 생성(generate) 된다고 하자.\n",
    "- 실제의 Pg(x)를 알 수 없으므로 분포를 나타내는 적당한 p(x|theta)를 만들어서 이것으로 Pg(x)를 모델링\n",
    "- 표현 범위 내에서 Theta를 조절하여 실제 분포 Pg(x)에 가깝도록 함.\n",
    "- 일반적인 방법 : 최대우도추정 (가장 있을법한 Theta)를 추정 값으로 선택하는 방법.\n",
    "- 즉 동일한 p(x|theta)에서 데이터 x1, ..., xn가 독립적으로 생성되었을 때 이들이 동시에 일어날 확률 Theta의 함수로 간주한 우도함수를 상정하고 이를 최대화하는 Theta를 파라미터의 추정 값으로 삼는다.\n",
    "\n",
    "maximum likelihood\n",
    "<img src ='https://wikimedia.org/api/rest_v1/media/math/render/svg/e50fc202373688dbc613797075e166fa335fa0ed'>\n",
    "\n",
    "Log (maximum likelihood)\n",
    "<img src ='https://wikimedia.org/api/rest_v1/media/math/render/svg/1684f8814e202ed92340b13bac4e1e53f25f5a3e'>\n",
    "\n",
    "Example 가우스 분포\n",
    "<img src = 'https://wikimedia.org/api/rest_v1/media/math/render/svg/26ba30da1c02ee9b8e7e39b68abe08cd5ded4b65'>\n",
    "\n",
    "<img src = 'https://wikimedia.org/api/rest_v1/media/math/render/svg/e7bf17aab9f310a93178b7149c5f932e8366ca64'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 볼츠만 머신\n",
    "#### 확률적 구조\n",
    "- 여러개의 유닛이 방향을 갖지 않는 결합으로 연결된 무향된 그래프가 있다고 하자. (각 유닛은 0,1 둘중 하나의 값 상태)\n",
    "- 볼츠만 머신이란 각각의 유닛이 갖는 상태 xi를 확률변수로 보았을 때 그래프에 M개 있는 유닛 모두의 상태 x=[x1,...xm]이 다음의 확룰 분포에 의해 주어지는 것을 말함\n",
    "- 볼츠만 분포의 구체적인 형태는 에너지 함수에 의해 정해짐.\n",
    "\n",
    "- A Boltzmann machine, like a Hopfield network, is a network of units with an \"energy\" defined for the network. It also has binary units, but unlike Hopfield nets, Boltzmann machine units are stochastic. The global energy, {\\displaystyle E} E, in a Boltzmann machine is identical in form to that of a Hopfield network:\n",
    "\n",
    "\n",
    "<img src ='http://cfile7.uf.tistory.com/image/2152B63D53DCCE511F64E2'>\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Boltzmann_machine\n",
    "\n",
    "결국 중요한 것은 에너지다. 에너지는 낮을 수록 안정적이고, 이 모델은 그래프가 가장 안정적인 경우를 가장 가능성(probable) 있는 상태로 판단한다(위 식에서 에너지가 낮을 수록 확률이 높다). 그럼 이 때 에너지 E의 구조를 보자.\n",
    "\n",
    "<img src ='https://wikimedia.org/api/rest_v1/media/math/render/svg/419a4966dae86dfb786dbeb6aadd3c38d9ec30d3'>\n",
    "\n",
    "- si는 i번째 노드의 값이고, 0 또는 1이다. θi는 노드의 bias다. wij는 노드i와 j를 잇는 엣지의 weight다. \n",
    "- 즉, 활성화(activate)된 모든 노드의 bias와 활성화된 노드간의 엣지 weight를 전부 더해서 음수를 취하면 에너지 E를 구할 수 있다.\n",
    "\n",
    "- 여기에서 Energy-Based model를 봅시다\n",
    "    - 각 상태(x)에 대해 에너지를 정의하고, 모든 원하는 상태들의 에너지가 최소가 되도록 에너지 함수의 파라미터를 학습하는 모델\n",
    "    - 에너지 기반의 확률 모델에서는 에너지 함수를 이용해 확률 분포를 다음과 같이 정의 \n",
    "    - 물리학에서의 볼츠만 분포 법칙을 신경망에 적용\n",
    "    - 뉴런은 볼츠만 분포 하에서 운동하는 분자라고 볼 수 있으며 뉴런의 State는 분자의 에너지 상태로 해석할 수 있음\n",
    "\n",
    "$P(x, h) = \\frac{e^{-\\text{energy}(x, h)}}{Z}$\n",
    "\n",
    "- 우리가 관찰할 수 있는 것은 x이기 때문에 우리가 모르는 h에 대해서는 marginal을 사용할 수밖에 없습니다.\n",
    "\n",
    "$P(x, h) = \\sum_h \\frac{e^{-\\text{energy}(x, h)}}{Z}$\n",
    "\n",
    "- 여기서 자유 에너지(free energy)라는 개념을 도입하여 봅시다.\n",
    "\n",
    "$\\text{FreeEnergy}(x) = – \\log \\sum_h e^{-\\text{Energy}(x, h)}$\n",
    "\n",
    "- ... \n",
    "\n",
    "$Z = \\sum_x e^{-\\text{FreeEnergy}(x)}$\n",
    "\n",
    "- ...\n",
    "\n",
    "$P(x) = \\frac{e^{-\\text{FreeEnergy}(x)}}{Z}$\n",
    "\n",
    "- EBM은 데이터의 log-likelihood를 이용해서 gradient descent 방법으로 학습 가능함 \n",
    "- 식에서와 같이 자유 에너지는 로그 도메인에서 에너지의 marginalization 입니다. 이제 모델의 파라미터를 θ, θ라고 나타내면, 확률 분포의 log-likelihood 그래디언트는 다음과 같이 계산할 수 있습니다.\n",
    "\n",
    "$\\frac{\\partial \\log P(x)} {\\partial \\theta} = \\frac{\\partial \\text{FreeEnergy}(x)}{\\partial \\theta} + \\frac{1}{Z} \\sum_{\\tilde{x}} e ^ {-\\text{FreeEnergy}(\\tilde{x})} \\frac{\\partial \\text{FreeEnergy}(\\tilde{x})}{\\partial \\theta} \\\\ \n",
    "= – \\frac{\\partial \\text{FreeEnergy}(x)}{\\partial \\theta} +  \\sum_{\\tilde{x}} P(\\tilde{x}) \\frac{\\partial \\text{FreeEnergy}(\\tilde{x})}{\\partial \\theta}$\n",
    "\n",
    "- 따라서 모든 트레이닝 셋에 대한 평균 log-likelihoood의 그래디언트는 다음과 같이 나타낼 수 있습니다.\n",
    "\n",
    "$E_{\\hat{P}} \\big[ \\frac{\\partial \\log P(x)}{\\partial \\theta} \\big] = -E_{\\hat{P}} \\big[ \\frac{\\partial \\text{FreeEnergy}(x)}{\\partial \\theta} \\big] +E_{P} \\big[ \\frac{\\partial \\text{FreeEnergy}(x)}{\\partial \\theta} \\big]$\n",
    "\n",
    "- 첫 번째 항은 Input 만 있으면 계산됨. 두 번째 항이 계산이 어려움. 모든 가능한 Input에 대해 계산하므로 정확하게 계산하는 것이 시간이 오래 걸림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 깁스 샘플링\n",
    "- 다변수 확률분포로부터 이를 따르는 변수를 생성하는 것은 간단하지 않음. 볼츠만 머신으로 지역적 마르코프성이라 불리는 성질을 이용하여 깁스 샘플링이라는 편리한 방법을 사용할 수 있음\n",
    "\n",
    "- 그럼 마르코프성 성질? 각각의 상태는 서로 독립이 아니라 이전의 상태에 영향을 받는다. 오늘의 날씨는 어제, 그제의 날씨와 무관하지 않다. 하루 전에 화창했다면, 하루 전 비가 왔을 때에 비해서, 오늘 맑을 확률이 더 높을 것이다. 조건부 확률로 표현하면 이렇게 된다.\n",
    "\n",
    "- 두 번쨰 항을 log-likelihood 그래디언트의 unbiased stochastic estimator를 얻을 수 있습니다. \n",
    "\n",
    "- 이와 관련하여 몇몇 연구에서는 다음과 같은 설명법을 사용하고 있습니다. Positive phase에서 x를 관측된 벡터로 고정하고 x가 주어진 상태에서 h를 샘플링하며, negative phase에서는 모델 자체에서 x와 h를 모두 샘플링합니다. 일반적으로 샘플링 또한 근사적인 샘플링만 가능하기 때문에 MCMC를 위해서 반복적으로 방법을 적용합니다.\n",
    "\n",
    "- MCMC는 Gibbs 샘플링을 기반으로 하고 있습니다. S=(S1,…,SN)의 분포에서의 Gibbs 샘플링은, 다음의 보조 샘플링 과정을 N번 하는 것으로 이루어집니다.\n",
    "$S_i \\sim P(S_i | S_{-i} = s_{-i})$\n",
    "\n",
    "- 보조 샘플링은 현재 샘플링하는 변수 한개를 제외하고는 나머지는 고정으로 두고 샘플링이 이루어집니다. N 번의 샘플링이 얻어지면 한 단계가 끝난 것입니다. 이 단계를 무한으로 반복하면 샘플들은 원래 분포  P(S)에 수렴하게 됩니다. 여기에 붙는 조건은 finite-state Markov Chain이 aperiodic이고 irreducible이어야만 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉 변수를 갖는 볼츠만 머신\n",
    "- v(가시변수),  h(은닉 변수), h의 값은 외부로부터 관측이 불가능하고 v만 관측할 수 있음.\n",
    " <img src ='http://cfile4.uf.tistory.com/image/2027E9404FDAC9A0284AC8'>\n",
    "\n",
    "- 대부분의 경우, 변수 x가 가진 요소 xi xi들의 값을 모두 관찰하기가 쉽지 않습니다. 혹은 관찰이 불가능할 때도 있습니다. 따라서 다루고자 하는 변수를 관찰 가능한 부분 x와 숨겨진 부분 h로 나누어 표시하기로 합시다.\n",
    "\n",
    "\n",
    "#### 제약 볼츠만 머신\n",
    "<img src ='https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Restricted_Boltzmann_machine.svg/220px-Restricted_Boltzmann_machine.svg.png'>\n",
    "\n",
    "- 유닛 간의 결합에 특별한 제약이 가해지는 것을 말함\n",
    "- 같은 layer내에서는 각 노드간의 커넥션을 없앤 BM을 RBM이라고 한다.\n",
    "- Restrict the connectivity to make learning easier\n",
    "    - only one layer of hidden units\n",
    "    - no connections between hidden units\n",
    "\n",
    "- Energy function을 다음과 같이 정의하면\n",
    "<img src ='http://deeplearning.net/tutorial/_images/math/06b7886e2624c3f9d97166acbe9a36bbf5ad0ec6.png'>\n",
    "\n",
    "- Bolzmann machine Energy Function\n",
    "- F\n",
    "$\\text{Energy}(x, h) = -b’x -c’h – h’Wx – x’Ux – h’Vh$\n",
    "\n",
    "\n",
    "- Free energy function은 다음과 같이 유도된다.\n",
    "\n",
    "<img src ='http://deeplearning.net/tutorial/_images/math/690d6785088eca2c3e557cce1e7248c61ee0e068.png'>\n",
    "\n",
    "- 대게의 경우 binary unit을 다루고, 또한 같은 layer 안에서는 connection이 없기 때문에 다음과 같은 성질을 가진다.\n",
    "\n",
    "<img src = 'http://deeplearning.net/tutorial/_images/math/4abe6f61702d2277ab84f6dbac446901ca22df9d.png'>\n",
    "\n",
    "- 식 (9), (10)의 성질을 이용해 식 (7)을 (2)번 식에 대입하여 유도하면 다음과 같이 각 확률이 activation function의 형태로 표현된다.\n",
    "\n",
    "<img src= 'http://deeplearning.net/tutorial/_images/math/2d501a4641b4a799e2dc4dfb32bb8b4be7178a7f.png'>\n",
    "\n",
    "- 식 (11)과 (12)는 실제 h와 v를 sampling 하는 확률로 사용이 된다. Free energy function 역시 (9)번 식의 성질을 이용하면 다음과 같이 유도 된다.\n",
    "\n",
    "<img src = 'http://deeplearning.net/tutorial/_images/math/82c8eaf19d0995f2940783368468cb66a8aea965.png'>\n",
    "\n",
    "- 식 (13)을 이용하면 아래와 같이 각 parameter들에 대한 update 식을 얻게 된다.\n",
    "\n",
    "<img src ='http://deeplearning.net/tutorial/_images/math/11f30506e02197abb6a70594b4a2b9d6b7a64211.png'>\n",
    "\n",
    "- 두 번째 항에 대한 요약!!!\n",
    "\n",
    "$\\frac{\\partial{\\text{ln}\\mathcal{L}(\\boldsymbol{\\theta}|\\boldsymbol{v})}}{\\partial{\\boldsymbol{\\theta}}}  \\approx  - \\langle  \\frac{\\partial}{\\partial{\\boldsymbol{\\theta}}}E(\\boldsymbol{v},\\boldsymbol{h}) \\rangle_{\\text{data}} + \\langle \\frac{\\partial}{\\partial{\\boldsymbol{\\theta}}}E(\\boldsymbol{v},\\boldsymbol{h})) \\rangle_{\\text{model}}$\n",
    "\n",
    "- 이제, 이 식을 MCMC Gibbs Sampler Contrastive Divergence를 사용해서 학습할 수 있다. \n",
    "- 위 식에서 input data에 대한 첫번째 항은 쉽게 구할 수 있지만 모델 전체에 대한 두번째 항은 구하기가 쉽지 않다. \n",
    "- 이를 Gibbs Sampling을 이용한 MCMC 추정을 사용해서, 모든 (v,h)에 대해 계산하지 않고 p(v|h)와 p(h|v)를 통해 v를 샘플링하여 근사할 수 있다.\n",
    "\n",
    "- 그러나 여전히 MCMC의 수렴조건을 계산하는 것이 까다로운데, 이를 CDk(Contrastive Divergence - k) 를 통해 위 근사값을 다시 한번 근사한다. 최종적인 log-likelihood 기울기(미분값)는 아래와 같다:\n",
    "\n",
    "$\\frac{\\partial{\\text{ln}\\mathcal{L}(\\boldsymbol{\\theta}|\\boldsymbol{v})}}{\\partial{\\boldsymbol{\\theta}}} = - \\langle  \\frac{\\partial}{\\partial{\\boldsymbol{\\theta}}}E(\\boldsymbol{v},\\boldsymbol{h}) \\rangle + \\langle  \\frac{\\partial}{\\partial{\\boldsymbol{\\theta}}}E(\\boldsymbol{v},\\boldsymbol{h}) \\rangle^{(k)}$\n",
    "\n",
    "- 이 때 k의 값은 1로 하여도 큰 문제가 없다고 알려져 있다. 지금까지의 과정에 파라메터 업데이트까지 포함하여 아래와 같이 정리할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조건부 분포\n",
    "- RBM에서 은닛 유닛 하나의 상태 hj는 다른 은닉 유닛의 상태와 독립.\n",
    "- 가시 변수의 값이 모두 정해져 있으면 은닉 변수의 확률 분포가 각각 개별로 정해진다.\n",
    "- 이런 성질때문에 hidden layer에 있는 각 unit들은 서로 conditionally independent하다.\n",
    "- 따라서, visible unit들과 hidden unit들의 joint configuration이라는 것을 다음과 같이 정의할 수 있다.\n",
    "- 입력 벡터 가 주어질 때 각각의 뉴런은 서로 독립이라고 가정하면, 은닉벡터 의 확률로 표시된다. \n",
    "- 마찬가지로 은닉벡터 h 가 주어지면 입력 뉴런들은 서로 독립이라고 가정한다. \n",
    "\n",
    "<img src ='http://cfile25.uf.tistory.com/image/1728A64250DAC0AD04D60B'>\n",
    "\n",
    "#### RBM과 자기부호화기\n",
    "- RBM은 auto encoder와 비슷한 역할을 함.\n",
    "- RBM은 가시층 유닛의 상태로 은닉층 유닛의 상태를 계산하는 조건부 분포포는 앞먹깅 신경망에서 로지스틱 함수를 활성화 함수로 갖는 유닛의 출력 계산식과 같음.\n",
    "- 차이는 학습(최적화 방법). 자기부호화기는 입력 x와 출력 x^의 값이 직접 가까워지도록 파라미터를 결정하지만 RBM에서는 가시층의 상태분포가 데이터의 생성분포에 가까워지도록 하습이 이루어짐.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM의 학습\n",
    "#### 깁스 샘플링을 사용한 기울기 계산\n",
    "\n",
    "- RBM training은 기본적으로 Gibbs sampling과 Contrastive divergence (CD-k)을 통해 진행된다.\n",
    "\n",
    "- RBM에서의 샘플링은 몇가지 이유에서 유용하게 사용됩니다. 먼저 학습 알고리즘 사용시, log-likelihood의 그래디언트 estimator를 얻는데 사용됩니다. 또한 데이터 분포가 제대로 반영되었는지 확인하기 위해 모델로부터 샘플을 생성하는데에도 사용됩니다.\n",
    "\n",
    "- 볼츠만 머신에서의 Gibbs 샘플링은 요소들간 서로 연결된 Gibbs 체인이 많아 수행 속도가 느렸지만, RBM에서 요소들간 서로 분리가 가능해졌기에 얻은 이득들이 있습니다. 첫번째는 자유에너지가 anallytically하게 계산이 가능하기 때문에 positive phase에서 샘플링을 할 필요가 없어졌으며, 두번째로 (x, h)는 단 두 단계의 Gibbs 체인만으로의 샘플링이 가능해졌습니다. 즉 x가 주어졌을 때 h를 샘플링 하고, 다음 그 h를 고정하고 새로운 x를 샘플링합니다.\n",
    "\n",
    "\n",
    "<img src= 'http://deeplearning.net/tutorial/_images/markov_chain.png'>\n",
    "\n",
    "- 위 그림과 같이 최초 observed data로부터 번갈아 가며 v->h->v... 이렇게 sampling을 진행하는 것이 Gibbs sampling이며 sampling은 식 (11), (12)에 의해 이루어진다. 이것이 무한이 반복되면 sample은 실제 확률로부터 얻어진 것과 동일하게 수렴하는 것이 보장이 된다. 하지만, 매 step마다 convege 할 때까지 수행한다면 계산량과 계산 시간에 치명적인 단점을 갖게 된다.\n",
    "\n",
    "- 이 문제를 해결하기 위해 소개되는 것이 바로 Contrastive divergence (CD-k)인데, CD-k에서는 이러한 과정을 k step에서 끝내게 된다. (Practical하게는 대부분의 경우 k = 1에서도 training이 된다고 하니, 신기할 따름이다.)\n",
    "\n",
    "- CD-k를 이용한 parameter update 하는 단계를 요약하면 다음과 같다.\n",
    "    - Training sample v로부터 식 (11)을 계산하고, 그 값을 이용해 h를 sampling 한다.\n",
    "    - v와 h의 외적을 계산한다 (positive gradient)\n",
    "    - h로부터 식 (12)를 계산하고 그로부터 v'를 sampling 한 다음, v'를 이용해 다시 h'을 sampling 한다.(Gibbs sampling step)\n",
    "    - v'와 h'의 외적을 구한다. (negative gradient.)\n",
    "\n",
    "<img src = 'https://upload.wikimedia.org/math/f/4/2/f42a6e46cb6768be459c5e4897ac44a0.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Belief Network\n",
    "- DBN은 RBM을 여러층으로 쌓은것이다. Higher level들의 각 node들이 입력 데이터의 abstraction된 값으로 표상된다라고 한다.\n",
    "\n",
    "<img src ='http://cfile1.uf.tistory.com/image/117FC45050DBAF780E786A'>\n",
    "\n",
    "- 위에서 보는 것처럼 RBM이 여러층으로 쌓여있는 형태이다. 하단의 directed belief nets라고 되어있어서 RBM과 다른것이 아닌가 하지만, 학습하는 중에는 RBM학습 방법과 동일하다. 하지만 학습이 끝난후에는 그림처럼 direction이 있다. 이것은 fine tuning을 할때 단순하게는 error back propagation을 사용하는데 그때에만 다시 weight를 다시 업데이트 해주기 위해서 인것.\n",
    "\n",
    "- 학습방법중 greedy layer-wise unsupervised training방법에 대해서 설명을 하자면, 이 학습 방법은 크게 두 부분으로 나뉜다. \n",
    "\n",
    "- 첫번째는 unsupervised pretraining이고 두번째는 supervised fine-tuning이다. \n",
    "\n",
    "- 첫번째의 pretraining방법의 역할은 네트워크상의 weights의 initial value를 결정하기 위함인데, 결국 입력데이터의 log-likelihood의 lower-bound를 최대화 하기위함인것이다. \n",
    "\n",
    "- supervised fine-tuning은 multi-layer perceptron에서 많이 사용하는 error backpropagation을 사용한다. 이 방법으로 error를 minimize하는 방향으로 weights를 튜닝해 나가는 방식이다.\n",
    "\n",
    "- 좀더 자세히 설명을 하자면, 총 학습은 4 step으로 나눠서 설명할 수 있을것 같다.\n",
    "\n",
    "\n",
    "#### (1) First step\n",
    "- RBM을 하나 세우고 학습.\n",
    "\n",
    "<img src = 'http://cfile29.uf.tistory.com/image/170B3F4050DCFF302119C2'>\n",
    "\n",
    "#### (2) Second step\n",
    "- 위에서 학습한 W1 weights를 고정시킨채로 RBM을 하나 더 올려서 학습. 두번째 RBM을 학습하기위한 입력은 Q(h1|v)에서 샘플된 h1이 된다. h1에 있는 노드의 값이라는것이 RBM에서 설명하였던 P(h=1|v)의 확률이지 어떤 대표될 수 있는 값이 아니기때문에 샘플되어 입력으로 들어가는 것. 이렇게 윗츠의 W2도 학습.\n",
    "\n",
    "<img src = 'http://cfile23.uf.tistory.com/image/1626884650DCFFCD1B5B27'>\n",
    "\n",
    "#### (3) Third step\n",
    "- 이렇게 계속 layer를 올리면서 동일한 방법으로 학습한다.\n",
    "<img src = 'http://cfile10.uf.tistory.com/image/2438CE3E50DD0103317C2A'>\n",
    "\n",
    "#### (4) Fourth step : discriminative fine-tuning\n",
    "- 마지막이 위에서 학습하여 결정된 weights이 neural network의 초기값이 된다. \n",
    "\n",
    "- 여기에 error back propagation 알고리즘으로 마지막 튜닝을 하는것이 fine-tuning이라는 과정인것이다. 아래그림이 3 hidden RBM layer를 가지는 DBN모델인데, 하나씩 RBM을 학습을 하고 난뒤에 마지막에 fine-tuning을 하는 과정을 나타내고 있다. 이렇게 학습하는 방법을 greedy layer-wise training이라고 한다.\n",
    "\n",
    "<img src = 'http://cfile25.uf.tistory.com/image/2441E33E50DD016E2D6953'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Boltzmann Machines\n",
    "\n",
    "- 깊은 볼츠만 기계 또는 DBM (Salakhutdinov and Hinton, 2009a)은 또 다른 종류의 깊고 생성적인 모델이다\n",
    "- DBN와는 달리, 그것은 전적으로 방향이 없는 모델입니다. (DBN은 유항 에지 -> 무향 에지로 치환)\n",
    "- RBM과 달리 DBM에는 몇 가지 잠재 변수 계층이 있습니다\n",
    "- 그러나 RBM과 마찬가지로 각 계층 내에서 각 변수는 상호 독립적이며 인접한 변수를 조건으로 합니다.\n",
    "\n",
    "![Figure 1-2](img/dbm1.png \"Figure 1-2\")\n",
    "\n",
    "- DBM에서는 은닉 유닛끼리의 결합이 있으므로 RBM과 같이 각 유닛의 상태에 대한 조건부 분포를 계산할 수는 없음.\n",
    "\n",
    "- **P(h(1), h(2) | v)를  q(h(1), h(2)| v) = 곱집합j q(hj(1) | v) * 곱집합k q(hk(2) | v) **\n",
    "- 근사분포는 다른 층의 은닉 변수가 서로 독립임을 나타낸다.\n",
    "- 평균장 근사(mean field approximation)이라는 방법을 사용하여 각 유닛의 상태를 계산함\n",
    "- 평균장 근사란, DBM처럼 변수 사이에 의존 관계가 없는 그래프 모델에 대해 이들 변수가 서로 독립이라고 가정하고 각 변수의 주변 분포를 근사적으로 계산하는 방법\n",
    "- 평균장 근사는 진짜 p(h(1), h(2) | v)에 가까운 분포를 최적화 계산을 통해 찾음. \n",
    "- 두 분포의 유사도는 쿨백-라이블러 발산으로 측정.\n",
    "- 쿨백 라이블러 발산 : https://ko.wikipedia.org/wiki/%EC%BF%A8%EB%B0%B1-%EB%9D%BC%EC%9D%B4%EB%B8%94%EB%9F%AC_%EB%B0%9C%EC%82%B0\n",
    "- 쿨백-라이블러 발산은 어떠한 확률분포 P가 있을 때, 샘플링 과정에서 그 분포를 근사적으로 표현하는 확률분포 Q를 P 대신 사용할 경우 엔트로피 변화를 의미한다.\n",
    "\n",
    "\n",
    "\n",
    "![Figure 1-3](img/dbm2.png \"Figure 1-1\")\n",
    "\n",
    "- 완전히 연결된 볼츠만 머신 (모든 유닛이 모든 다른 유닛에 연결된 상태)과 비교할 때, DBM은 RBM이 제공하는 것과 유사한 몇 가지 이점을 제공합니다. 특히 그림에서 보듯이, DBM layers는 한쪽면에 홀수 레이어가 있고 다른 한쪽면에 레이어가있는 두 파트 그래프로 구성 될 수 있습니다.\n",
    "\n",
    "<img src= 'https://image.slidesharecdn.com/p05deepboltzmannmachinescvpr2012deeplearningmethodsforvision-120822081928-phpapp01/95/p05-deep-boltzmann-machines-cvpr2012-deep-learning-methods-for-vision-25-728.jpg?cb=1345623664'>\n",
    "\n",
    "\n",
    "- 이것은 짝수 계층의 변수를 조건으로 할 때 홀수 계층의 변수가 조건 적으로 독립적이라는 것을 즉시 의미합니다. 물론, 홀수 층의 변수를 조건으로 할 때, 짝수 층의 변수는 조건 적으로 독립적이 됩니다.\n",
    "\n",
    "- DBM의 이분법적 구조는 DBM에서 조건부 분포를 결정하기 위해 RBM의 조건부 분포에 대해 이전에 사용한 것과 동일한 방정식을 적용 할 수 있음을 의미합니다. \n",
    "\n",
    "- 레이어 내의 유닛은 인접 레이어의 값이 주어지면 서로 조건부로 독립적이므로 이진 변수를 통한 분포는 각 단위가 활성화 될 확률을 제공하는 베르누이 매개 변수로 완전히 설명 될 수 있습니다. \n",
    "\n",
    "\n",
    "![Figure 1-6](img/dbm6.png \"Figure 1-6\")\n",
    "\n",
    "- 이분법적 구조는 깊은 Boltzmann 기계에서 깁스 샘플링을 만듭니다. \n",
    "- Gibbs 샘플링에 대한 순진한 접근법은 한 번에 하나의 변수 만 업데이트하는 것입니다. RBM은 보이는 모든 유닛이 한 블록에서 업데이트되고 모든 숨겨진 유닛이 두 번째 블록에서 업데이트되도록 허용합니다. \n",
    "\n",
    "- 한 레이어는 하나의 레이어로 구성된 블록을 업데이트 할 때마다 반복적으로 레이어가있는 DBM에 업데이트가 필요하다고 가정할 수 있습니다. 대신 단 두 번의 반복으로 모든 유닛을 업데이트 할 수 있습니다. \n",
    "- 깁스 샘플링은 두 개의 업데이트 블록으로 나눌 수 있습니다. 하나는 모든 짝수 레이어 (보이는 레이어 포함)를 포함하고 다른 하나는 모든 홀수 레이어를 포함합니다. \n",
    "- RBM과 마찬가지로 CD를 통해서 계산함. 이때 CD의 반복 횟수는 단독 RBM보다는 늘려야 한다고 알려져 있음.\n",
    "\n",
    "- 양극성 DBM 연결 패턴으로 인해, 짝수 레이어가 주어지면, 홀수 레이어를 통한 분포는 계승 (factorial)이므로, 동시에 그리고 독립적으로 블록으로 샘플링 될 수 있습니다. 마찬가지로, 홀수 레이어가 주어지면, 짝수 레이어는 동시에 그리고 독립적으로 블록으로 샘플링 될 수 있습니다. 확률 적 최대 우도 알고리즘으로 훈련 할 때 효과적인 샘플링이 특히 중요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.4.1 Interesting Properties\n",
    "- DBM은 DBN 후에 개발되었습니다. DBN과 비교할 때 사후 분포 P(h|v)는 DBM에 대해 더 간단합니다. \n",
    "- 다소 반 직관적으로,이 사후 분포의 단순성은 사후의 더 근사를 허용합니다. DBN의 경우 숨겨진 유닛의 평균값에 대한 합리적인 값은 S 자형을 사용하는 MLP에서 네트워크를 통한 상향 통과에 의해 제공 될 수 있다고 생각되는 경험적으로 근사화 된 근사 추론 절차를 사용하여 분류를 수행합니다 \n",
    "- 정품 인증 기능 및 원래 DBN과 동일한 가중치를 제공합니다. 임의의 분포 Q (h)는 로그 가능도 (log-likelihood)에 대한 변하 적 하한을 구하는데 사용될 수있다. 따라서 이 경험적 절차는 우리가 그러한 경계를 얻을 수있게 해줍니다. \n",
    "\n",
    "- DBN에서 경험적 MLP 기반 추론 절차는 이러한 상호 작용을 설명 할 수 없으므로 결과 Q는 아마도 최적 상태에서 멀어진 것입니다.\n",
    "- DBM에서 한 레이어 내의 모든 숨겨진 유닛은 다른 레이어를 기준으로 조건부 독립적입니다. 이러한 계층 간 상호 작용의 결여는 고정 소수점 방정식을 사용하여 실제로 변이 하한값을 최적화하고 실제 최적의 평균 필드 기대 값 (일부 수치 허용 오차 이내)을 찾아 낼 수 있습니다. \n",
    "- 적절한 평균 필드를 사용하면 DBM이 대략적인 추론 절차를 수행 할 수 있습니다 하향식 피드백 상호 작용의 영향. 이것은 인간의 뇌가 많은 하향식 피드백 연결을 사용하는 것으로 알려져 있기 때문에 DBM을 신경 과학의 관점에서 보면 흥미 롭다. \n",
    "- 이 속성 때문에 DBM은 실제 신경 과학 현상의 계산 모델로 사용되었습니다 (Series et al., 2010; Reichert et al., 2011). DBM의 불행한 속성은 비교적 샘플링이 상대적으로 어렵다는 것입니다. \n",
    "- DBN은 상위 레이어 쌍에서 MCMC 샘플링 만 사용해야 합니다. 다른 층은 샘플링 과정이 끝난 후 한 번의 실제 샘플링 단계에서만 사용됩니다. DBM에서 샘플을 생성하려면 모든 레이어에서 MCMC를 사용해야하며, 모델의 모든 레이어는 모든 마코프 체인 전환에 참여해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5 Boltzmann Machines for Real-Valued Data\n",
    "- 가시층이 이진 유닛으로 이루어진 경우, 응용 범위가 제한적이라 가우시안 유닛(Gaussian unit)이 고안되었음. \n",
    "- 볼츠만 머신은 원래 바이너리 데이터와 함께 사용하기 위해 개발되었지만 이미지 및 오디오 모델링과 같은 많은 애플리케이션은 실제 값보다 확률 분포를 나타낼 수 있어야합니다. \n",
    "- 경우에 따라 [0, 1] 구간의 실수 값 데이터를 이진 변수의 기대치로 나타낼 수 있습니다. 예를 들어, Hinton (2000)은 훈련 세트의 그레이 스케일 이미지를 [0,1] 확률 값으로 정의합니다. 각 픽셀은 이진 값이 1이 될 확률을 정의하고 이진 픽셀은 모두 서로 독립적으로 샘플링됩니다. \n",
    "- 이것은 그레이 스케일 이미지 데이터 세트에서 바이너리 모델을 평가하는 일반적인 절차입니다. 그러나 이론적으로는 만족스러운 접근 방식은 아니며 이러한 방식으로 독립적으로 샘플링 된 이진 이미지는 노이즈가 있습니다. 이 섹션에서는 실제 값 데이터보다 확률 밀도를 정의하는 볼츠만 머신을 제시합니다.\n",
    "\n",
    "\n",
    "### 20.5.1 Gaussian-Bernoulli RBMs\n",
    "- 가시층에 가우시안 유닛을 사용하고 은닉층에는 이진 유닛을 사용하는 경우\n",
    "- 제한된 볼츠만 기계는 많은 지수적 가족 조건부 분포에 대해 개발될 수 있다 (Welling et al., 2005). \n",
    "- 이 중 가장 공통적 인 것은 이진 숨겨진 단위와 실수 값 가시 단위가 있는 RBM이며 가시적 단위에 대한 조건부 분포는 가우시안 분포이며 그 평균은 숨겨진 단위의 함수입니다.\n",
    "- Gaussian-Bernoulli RBM을 매개 변수화하는 많은 방법이 있습니다. 하나의 선택은 가우시안 분포에 대해 공분산 행렬 또는 정밀도 행렬을 사용할지 여부입니다. 여기서 우리는 정밀 배합을 제시합니다. 공분산 공식을 얻기위한 수정은 간단합니다. 조건부 분포를 원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.2 Undirected Models of Conditional Covariance\n",
    "- Gaussian RBM은 실수 값 데이터에 대한 표준 에너지 모델 이었지만, Ranzato et al. (2010a)는 가우스 RBM 유도 바이어스가 실제 데이터의 일부 유형, 특히 자연 이미지에 존재하는 통계적 변화에 적합하지 않다고 주장합니다. \n",
    "- 문제는 자연 이미지에있는 많은 정보 내용이 원시 픽셀 값이 아닌 픽셀 간의 공분산에 포함된다는 것입니다. 즉, 이미지의 유용한 정보가있는 곳은 절대 값이 아닌 픽셀 간의 관계입니다. \n",
    "- Gaussian RBM은 숨겨진 유닛이 주어진 입력의 조건부 평균 만 모델링하기 때문에 조건부 공분산 정보를 캡처 할 수 없습니다. \n",
    "- 이러한 비판에 대응하여 실제 값 데이터의 공분산을 더 잘 설명하려는 대체 모델이 제안되었습니다. 이러한 모델에는 평균 및 공분산 RBM (mcRBM1), t-분포 (mPoT) 모델의 평균 곱, 스파이크 및 슬랩 RBM (ssRBM)\n",
    "\n",
    "- 평균 및 공분산 RBM mcRBM은 숨겨진 단위를 사용하여 관찰 된 모든 단위의 조건부 평균 및 공분산을 독립적으로 인코딩합니다. \n",
    "- ThemcRBM 숨김 계층은 평균 단위와 공분산 단위의 두 가지 단위 그룹으로 나뉩니다. 조건부 평균을 모델링하는 그룹은 단순히 가우스 RBM입니다. 나머지 절반은 아래에 설명 된대로 조건부 공분산 구조를 모델링하는 구성 요소 인 cRBM이라고도하는 공분산 RBM (Ranzato 등, 2010a)입니다.\n",
    "\n",
    "\n",
    "### Spike and slab RBM\n",
    "- Ref :  http://e0en.tumblr.com/post/45405840602/spike-and-slab-rbm%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80\n",
    "- 연속적인 값을 갖는 입력이 주어졌을 때 가장 손쉽게 선택하는 RBM 모델은 가우시안-베르누이 RBM (이하 GRBM)이다. 이 녀석은 은닉 노드가 주어졌을 때의 데이터의 조건부 분포를  분산 1의 정규분포라고 가정한다. 은닉 노드는 일반적인 RBM과 똑같이 베르누이 분포에서 얻어지는 이진 값을 갖는다.\n",
    "\n",
    "- GRBM이 학습하는 분포는 결국 여러 개의 동일한 모양의 정규분포의 혼합 형태가 되는데, 이런 특징은 영상 특징 추출 시에는 불리하게 작용한다.\n",
    "- 영상의 경우, 명도/대비의 변화가 데이터의 분산에서 가장 큰 부분을을 차지하지만 사실 이것들은 중요하지 않다. 그러나 구형 가우시안 분포의 혼합으로 이 문제를 해결하려다 보면 명도/대비의 방향으로 가우시안 분포들이 늘어서는 양상이 된다. 따라서 명도/대비가 변할 때마다 은닉 노드의 값이 변하고, 이는 영상 분류 등의 작업에 적절하지 못하다.\n",
    "\n",
    "- 이걸 해결하려면 두 가지 방법을 쓸 수 있다.\n",
    "    1. 데이터의 분산 행렬을 학습한다.\n",
    "    2. 은닉 노드가 연속적인 값을 갖는 것을 허용한다.\n",
    "    \n",
    "    \n",
    "- 1번의 방법을 택한 것이 분산 행렬을 학습하는 (mean-)covariance RBM이다. 그러나 이 모델은 데이터의 조건부 분포 계산 과정에서 모두 분산 행렬의 역행렬 계산을 요구하는데, 심지어 분산 행렬이 은닉 노드의 값에 의존하기 때문에 미리 계산해서 저장해 둘 수도 없다. 따라서 은닉 노드에 대해 적분을 취하고 Hybrid Monte Carlo를 사용하는 등 그 과정이 복잡하다.\n",
    "- 2번을 그냥 단순하게 받아들이면 은닉 노드에도 가우시안 분포를 부여하면 된다고 생각하기 쉬운데, 이렇게 하면 학습 과정이 수치적으로 매우 불안정해지는데다가 명도/대비에 따라 은닉 노드의 값이 안 변하는 게 아니므로 사실상 얻는 이점이 없다.\n",
    "- 2번의 아이디어를 좀 더 발전시킨 것이 spike and slab RBM (ssRBM)이다. 기존의 은닉 노드 하나를 이진 값을 갖는 spike 노드와 연속적인 값을 갖는 slab 노드의 곱으로 표현하는 방법이다.\n",
    "- 이렇게만 두면 spike 노드의 값은 1로 고정되고, slab 노드의 값만 변화하면서 데이터의 분포를 나타내도록 학습되지 않을까 하는 우려가 있을 수 있고, 실제로도 대책없이 spike 노드만을 도입하면 이렇게 학습이 되지만, slab 노드 값에 대한 regularizer 항의 도입으로 이 문제는 해결이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.6 Convolutional Boltzmann Machine\n",
    "- 9장에서 볼 수 있듯이, 이미지와 같은 매우 높은 차원의 입력은 기계 학습 모델의 계산, 메모리 및 통계 요구 사항에 큰 부담을 줍니다. \n",
    "- 이산 회선에 의한 행렬 곱셈을 몰 커널로 대체하는 것은 변환 불변의 공간 또는 시간 구조를 갖는 입력에 대해 이러한 문제를 해결하는 표준 방법입니다. \n",
    "- 복잡한 컨볼 루션 네트워크는 일반적으로 각 연속 계층의 공간 크기가 감소하도록 풀링 작업을 필요로 합니다. 피드 포워드 컨볼루션 네트워크는 풀링 할 요소의 최대 값과 같은 풀링 기능을 사용하는 경우가 많습니다. 이를 에너지 기반 모델 설정으로 일반화하는 방법이 명확하지 않습니다. \n",
    "\n",
    "![crbm1](img/crbm1.png \"CRBM1\")\n",
    "\n",
    "\n",
    "- 우리는 바이너리 검출기 유닛에 대해 바이너리 풀링 유닛을 도입 할 수 있고, 제약 조건을 위반할 때마다 에너지 함수를 설정하는 것\n",
    "- lee et al. (2009)는 probabilistic max pooling (컨벌루션 피드 포워드 네트워크의 앙상블을 암시 적으로 구성하는 기술인 \"확률 적 풀링\"과 혼동하지 말아야 함)이라는이 문제에 대한 솔루션을 개발했습니다. \n",
    "\n",
    "- 확률론적 최대 풀링 (pooling)의 배후에 있는 전략은 탐지기 유닛을 제한하여 최대 한 번에 하나씩 활성화 할 수 있도록하는 것입니다. 이는 총 n + 1 개의 상태 (각 검출기 유닛이 켜져있는 상태와 모든 검출기 유닛에 해당하는 추가 상태가 일치함)를 의미합니다. \n",
    "- 풀링 유닛은 감지기 유닛 중 하나가 켜져있는 경우에만 켜집니다. 모든 단위가 ff 인 상태에는 에너지 0이 할당됩니다. 우리는 이것을 생각할 수 있는데, 하나의 변수가 하나의 상태 인 모델을 설명하거나, 변수의 n + 1 개의 변수를 제외한 모든 변수에 에너지 ∞를 할당하는 변수가없는 모델이라고 생각할 수 있습니다.\n",
    "\n",
    "- 효율성은 높지만 확률 론적 최대 풀링은 검출기 유닛을 상호 배타적으로 만든다. 이는 일부 상황에서는 유용한 정규화 제약 조건이거나 다른 상황에서는 모델 용량에 대한 유해한 한계 일 수있다. \n",
    "- 또한 중첩하는 풀링 영역을 지원하지 않습니다. 일반적으로 피드 포워드 컨볼 루션 네트워크에서 최상의 성능을 얻기 위해서는 겹치는 풀링 영역이 필요하므로이 제약은 볼츠만 머신의 컨볼 루션 성능을 크게 저하시킵니다 .\n",
    "\n",
    "- Lee et al. (2009)은 확률 론적 최대 풀링이 볼츠만 (convolutional) 깊은 볼츠만 기계를 만드는 데 사용될 수 있음을 보여 주었다.이 모델은 입력의 누락 부분을 채우는 것과 같은 연산을 수행 할 수있다.\n",
    "- 지능적으로 매력적이지만,이 모델은 실제 업무를 수행하기가 쉽지 않으며 일반적으로 감독 학습을 통해 학습 된 전통적 길쌈 네트워크처럼 분류기만큼 잘 수행되지 않습니다.\n",
    "\n",
    "- 많은 컨볼 루션 (convolutional) 모델은 많은 다른 크기의 입력으로 동등하게 잘 작동합니다. \n",
    "- 볼츠만 머신의 경우 다양한 이유로 입력 크기를 변경하는 것이 다릅니다. 파티션 기능은 입력 변경의 크기에 따라 변경됩니다. \n",
    "- 또한 많은 컨볼 루션 네트워크는 입력 크기에 비례하여 풀링 영역의 크기를 확대하여 크기 불변성을 달성하지만 scaling Boltzmann 시스템 풀링 영역은 어색합니다. \n",
    "\n",
    "- 기존의 길쌈 신경망은 고정 된 수의 풀링 유닛을 사용하고 가변 크기 입력의 고정 크기 표현을 얻기 위해 풀링 영역의 크기를 동적으로 증가시킬 수 있습니다. 볼츠만 머신의 경우 대형 풀링 영역이 순진한 접근 방식에 비해 저렴 해집니다. \n",
    "- Lee 외의 접근법. (2009)는 상호 배타적 인 동일한 풀링 영역에서 검출기 유닛을 구성하는 것은 계산적 문제를 해결하지만 가변 크기 풀링 영역을 허용하지 않는다. 예를 들어, 우리는 2x2 확률 론적 최대 풀링 과다 검출기 단위를 학습하여 에지 검출기.\n",
    "- 이는 각 에지의 단지 하나만이 각 2x2 영역에 나타날 수있는 제한을 강요합니다. 우리가 각 방향에서 입력 이미지의 크기를 50 % 증가 시키면 그에 상응하여 가장자리 수가 증가 할 것으로 예상됩니다. \n",
    "- 대신에 풀링 영역의 크기를 각 방향에서 50 % 씩 3x3으로 증가 시키면 이제는 상호 배타성 제약 조건이 각 에지가 3x3 영역에서만 한 번 나타날 수 있습니다. 이런 방식으로 모델의 입력 이미지를 생성 할 때 모델은 밀도가 낮은 에지를 생성합니다. \n",
    "- 물론,이 문제는 고정 된 크기의 출력 벡터를 생성하기 위해 모델이 다양한 양의 풀을 사용해야하는 경우에만 발생합니다. probabilisticmax 풀링을 사용하는 모델은 모델의 출력이 입력 이미지에 비례하여 크기가 조정될 수있는 피쳐 맵인 한 가변 크기의 입력 이미지를 허용 할 수 있습니다. \n",
    "- 이미지의 경계에있는 픽셀 또한 일부 exac - Boltzmann 기계의 연결이 대칭이라는 사실에 기인합니다. \n",
    "- 암묵적으로 입력을 제로 패드하지 않으면 보이지 않는 유닛보다 숨겨진 유닛이 적고 이미지의 경계에있는 보이는 유닛은 더 적은 숨겨진 유닛의 수용 영역에 있기 때문에 잘 모델링되지 않습니다. \n",
    "- 그러나 입력을 암묵적으로 제로 패드하면 경계의 숨겨진 유닛이 더 적은 입력 픽셀에 의해 구동되고 필요할 때 활성화되지 않을 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.7 Boltzmann Machines for Structured or Sequential Outputs\n",
    "- 구조화 된 출력 시나리오에서 우리는 어떤 입력에서 일부 출력으로 매핑 할 수있는 모델을 훈련시키고 각기 다른 입력은 서로 관련되어 있으며 일부 제약 조건을 따라야합니다. \n",
    "- 예를 들어, 음성 합성 작업에서 y는 파형이고 전체 파형은 일관된 발성처럼 들리 죠. 항목 간의 관계를 나타내는 자연스러운 방법은 확률 분포 p (y | x)를 사용하는 것입니다. Boltzmann 머신은 모델 조건부 배포로 확장되어이 확률 모델을 제공 할 수 있습니다. \n",
    "- Boltzmann 머신을 사용한 조건부 모델링의 동일한 도구는 구조화 된 출력 작업뿐만 아니라 시퀀스 모델링에도 사용될 수 있습니다. 후자의 경우, input x를 output y로 매핑하는 대신 모델은 일련의 변수에 대해 확률 분포 p (x (1), ..., x (τ))를 추정해야합니다. \n",
    "\n",
    "\n",
    "### RNN-RBM\n",
    "<img src= 'http://danshiebler.com/img/rnnrbm_color.png'>\n",
    "\n",
    "- RNN-RBM은 RNN에 의해 매개 변수가 결정되는 일련의 제한된 볼츠만 기계로 생각할 수 있습니다. 다시 말해, RBM은 보이는 레이어와 숨겨진 레이어의 2 개의 레이어가있는 신경망입니다. 각 보이는 노드는 각 숨겨진 노드에 연결되지만 (반대의 경우도 마찬가지 임) 가시적으로 보이거나 숨겨진 연결은 없습니다.\n",
    "\n",
    "- Ref : http://danshiebler.com/2016-08-17-musical-tensorflow-part-two-the-rnn-rbm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.8 Other Boltzmann Machines\n",
    "\n",
    "- 볼츠만 기계의 다른 많은 변형이 가능합니다. 볼츠만 기계는 다른 교육 기준으로 확장 될 수 있습니다. \n",
    "- 우리는 생성 기준 log p (v)를 대략 최대화하도록 훈련 된 볼츠만 기계에 중점을 두었습니다. 대신에 log p (y|v)를 최대화하는 것을 목표로하는 차별적인 RBM을 훈련하는 것도 가능하다 (Larochelle and Bengio, 2008). \n",
    "\n",
    "- 이 접근법은 생성 및 차별 기준의 선형 조합을 사용할 때 종종 가장 잘 수행됩니다. 불행히도, RBM은 적어도 기존의 방법론을 사용하여 MLP만큼 강력한 감독자가 아닌 것처럼 보입니다.\n",
    "- 실제로 사용되는 대부분의 볼츠만 기계는 에너지 함수에서 2차 상호 작용만 갖습니다. 즉, 에너지 함수는 여러 용어의 합이며 각 개별 용어는 두 개의 임의 변수 사이의 곱을 포함합니다. 또한 에너지 함수 항이 많은 변수들 사이의 곱을 포함하는 고차원 Boltzman 기계를 훈련하는 것이 가능하다 (Sejnowski, 1987). \n",
    "\n",
    "- one-hot class 변수에 의한 곱셈은 어떤 클래스가 존재하는지에 따라 보이는 단위와 숨겨진 단위 사이의 관계를 변경할 수 있습니다 (Nair and Hinton, 2009). \n",
    "- 고차원적인 상호 작용을 사용하는 최근의 한 예는 두 개의 숨겨진 유닛 그룹과 볼 수있는 유닛과 클래스 레이블 y와 상호 작용하는 한 그룹의 숨겨진 유닛과 상호 작용하는 숨겨진 유닛 그룹을 가진 볼츠만 머신입니다 v 입력 값 (Luo et al., 2011).\n",
    "\n",
    "- 이것은 일부 숨겨진 유닛이 클래스와 관련된 기능을 사용하여 입력을 모델링하는 것을 배우도록 유도하는 것으로 해석 될 수 있습니다. v의 샘플이 현실이면서도 결정을 내리는 데 필요한 불필요한 세부 사항을 설명하는 추가 숨겨진 유닛을 학습하는 것으로 해석 될 수 있습니다. 예제의 클래스. 고차원 상호 작용의 또 다른 용도는 일부 기능을 게이트하는 것입니다.\n",
    "\n",
    "- Sohn et al. (2013)은 각 가시적 단위와 관련된 바이너리 마스크 변수와 3차 상호 작용이 있는 볼츠만 (Boltzmann) 기계를 도입했습니다. 이러한 마스킹 변수가 0으로 설정되면 숨겨진 장치에서 보이는 장치의 영향을 제거합니다. 이것은 분류 문제와 관련없는 가시적 단위가 클래스를 추측하는 추론 경로에서 제거 될 수있게합니다. 일반적으로 볼츠만 기계 프레임 워크는 지금까지 탐구 된 것보다 더 많은 모델 구조를 허용하는 풍부한 모델 공간입니다. \n",
    "\n",
    "- 새로운 형태의 볼츠만 기계를 개발하려면 새로운 신경망 층을 개발하는 것보다 더 많은 창의력이 필요합니다. 왜냐하면 볼츠만 기계를 사용하는 데 필요한 모든 다른 조건부 분포의 추적성을 유지하는 에너지 기능을 찾는 것이 종종 어렵기 때문입니다. 혁신을 위해 필드가 필요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
